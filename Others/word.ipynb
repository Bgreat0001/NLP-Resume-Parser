{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e62af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import nltk \n",
    "import spacy\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "import constants as cs\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import utils\n",
    "import spacy\n",
    "import pprint\n",
    "from spacy.matcher import Matcher\n",
    "import multiprocessing as mp \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544ec798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='1.pdf'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2 as pdf\n",
    "file = open('1.pdf', 'rb')\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97edf6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._reader.PdfFileReader at 0x294e5c2e880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_reader = pdf.PdfFileReader(file)\n",
    "pdf_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5127bf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Name  : ROBERT  \\n \\n9475838374  \\nEmail:  info@qwikresume.com  Website:  www.qwikresume.com  \\nLinkedIn:  linkedin.com/qwikresume  Address:  1737 Marshville  Road,  \\nAlabama.  \\nObjective   \\nOver 6 years  of IT industry  experience  with 4+ years  of experience  as Mobile  application  \\ndeveloper in the field of Android. Experience in developing front end applications for Android  \\nphones.  Experience  developing  mobile  applications  on Android  platform,  building  Custom  UI using \\nViews,  ViewGroups,  Layouts,  Widgets  and graphics  that scale  based  on the screen  size using  9- \\npatch  images,  localization, testing  and publishing  the applications  to the Android  Market.  \\n \\nSkills   \\nPython,  Java,  C, Javascript,  Matlab,  R. \\n \\nWork  Experience   \\nAndroid  Developer  \\nABC Corporation  \\xad January  2011  – March  2012  \\n• Environment  Eclipse  IDE, Android  Studio,  GenyMotion,  Java,  Android  SDK, Android  \\nDevelopment Tools (ADT), JSON, XML, \\n• Involved  in the  full life cycle  of the project including analysis  design,  development,  debugging,  \\ntesting,  and deployment.  \\n• Developed  the application  from specifications  and requirement  gathering.  \\n• Independently  handled  modules,  scope,  analysis,  design,  build,  test the code,  debug  and \\nimplement  application.  \\n• Developed  products  section  of the application  which  provided  Multiple  Activities,  Custom  \\nAdapters,  Base Adapter,  List views,  Links,  Web View,  Text Views  and so on. \\n• Developed  Navigation  Drawer  for the application,  which  provides  better  navigation  of apps \\nfeatures.  \\n• Created  new UI Screens  and key resource  for layout  UI work  utilizing  xml, Shape  Drawable,  \\nText View,  List View,  Web View,  Buttons,  Activities,  and Frame  Layout.  \\nAndroid  Developer  \\nABC Corporation  \\xad 2006  – 2011  \\n• Helped  Develop  Insight,  which  is a tablet  application  that retrieves  data from a CPE and \\ndisplays  it \\n• This is done  to debug  the DSL activity  in someones  home  \\n• Pulled  info from a cloud  server  and coded  it onto a  tablet  \\n• Worked  on UI and backend  construction  \\n• Connected  to various  computer  boards  where  I retrieved Wi -Fi information from  a server  - \\nDebugged  code  that was previously  worked  on by an outsourced  company  \\nEducation   \\nIT Technology - 2011(Gyumri  Information  Technologies  Center)  '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_reader.getNumPages()\n",
    "page1 = pdf_reader.getPage(0)\n",
    "resumeText = page1.extractText()[:5000]\n",
    "resumeText      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d3b69f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Name : ROBERT 9475838374 Email: info@qwikresume.com Website: www.qwikresume.com LinkedIn: linkedin.com/qwikresume Address: 1737 Marshville Road, Alabama. Objective Over 6 years of IT industry experience with 4+ years of experience as Mobile application developer in the field of Android. Experience in developing front end applications for Android phones. Experience developing mobile applications on Android platform, building Custom UI using Views, ViewGroups, Layouts, Widgets and graphics that scale based on the screen size using 9- patch images, localization, testing and publishing the applications to the Android Market. Skills Python, Java, C, Javascript, Matlab, R. Work Experience Android Developer ABC Corporation January 2011 March 2012 Environment Eclipse IDE, Android Studio, GenyMotion, Java, Android SDK, Android Development Tools (ADT), JSON, XML, Involved in the full life cycle of the project including analysis design, '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanResume(resumeText):\n",
    "    #resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "   # resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    #resumeText = re.sub(r'\\n', ',', resumeText)\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "   # resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "   # resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "   # resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*,-/<=>?[]^`{|}~\"\"\"), ' ', resumeText)\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    return resumeText\n",
    "clean = cleanResume(resumeText)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d33289a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name : ROBERT 9475838374 Email: info@qwikresume.com Website: www.qwikresume.com LinkedIn: linkedin.com/qwikresume Address: 1737 Marshville Road, Alabama. Objective Over 6 years of IT industry experience with 4+ years of experience as Mobile application developer in the field of Android. Experience in developing front end applications for Android phones. Experience developing mobile applications on Android platform, building Custom UI using Views, ViewGroups, Layouts, Widgets and graphics that scale based on the screen size using 9- patch images, localization, testing and publishing the applications to the Android Market. Skills Python, Java, C, Javascript, Matlab, R. Work Experience Android Developer ABC Corporation January 2011 March 2012 Environment Eclipse IDE, Android Studio, GenyMotion, Java, Android SDK, Android Development Tools (ADT), JSON, XML, Involved in the full life cycle of the project including analysis design,'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(clean.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb8a22",
   "metadata": {},
   "source": [
    "# Trail tokenize and extract skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6798b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', ':', 'ROBERT', '9475838374', 'Email', ':', 'info', '@', 'qwikresume.com', 'Website', ':', 'www.qwikresume.com', 'LinkedIn', ':', 'linkedin.com/qwikresume', 'Address', ':', '1737', 'Marshville', 'Road', ',', 'Alabama', '.', 'Objective', 'Over', '6', 'years', 'of', 'IT', 'industry', 'experience', 'with', '4+', 'years', 'of', 'experience', 'as', 'Mobile', 'application', 'developer', 'in', 'the', 'field', 'of', 'Android', '.', 'Experience', 'in', 'developing', 'front', 'end', 'applications', 'for', 'Android', 'phones', '.', 'Experience', 'developing', 'mobile', 'applications', 'on', 'Android', 'platform', ',', 'building', 'Custom', 'UI', 'using', 'Views', ',', 'ViewGroups', ',', 'Layouts', ',', 'Widgets', 'and', 'graphics', 'that', 'scale', 'based', 'on', 'the', 'screen', 'size', 'using', '9-', 'patch', 'images', ',', 'localization', ',', 'testing', 'and', 'publishing', 'the', 'applications', 'to', 'the', 'Android', 'Market', '.', 'Skills', 'Python', ',', 'Java', ',', 'C', ',', 'Javascript', ',', 'Matlab', ',', 'R.', 'Work', 'Experience', 'Android', 'Developer', 'ABC', 'Corporation', 'January', '2011', 'March', '2012', 'Environment', 'Eclipse', 'IDE', ',', 'Android', 'Studio', ',', 'GenyMotion', ',', 'Java', ',', 'Android', 'SDK', ',', 'Android', 'Development', 'Tools', '(', 'ADT', ')', ',', 'JSON', ',', 'XML', ',', 'Involved', 'in', 'the', 'full', 'life', 'cycle', 'of', 'the', 'project', 'including', 'analysis', 'design', ',']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(clean)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e2c12c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Name : ROBERT 9475838374 Email: info@qwikresume.com Website: www.qwikresume.com LinkedIn: linkedin.com/qwikresume Address: 1737 Marshville Road, Alabama.', 'Objective Over 6 years of IT industry experience with 4+ years of experience as Mobile application developer in the field of Android.', 'Experience in developing front end applications for Android phones.', 'Experience developing mobile applications on Android platform, building Custom UI using Views, ViewGroups, Layouts, Widgets and graphics that scale based on the screen size using 9- patch images, localization, testing and publishing the applications to the Android Market.', 'Skills Python, Java, C, Javascript, Matlab, R. Work Experience Android Developer ABC Corporation January 2011 March 2012 Environment Eclipse IDE, Android Studio, GenyMotion, Java, Android SDK, Android Development Tools (ADT), JSON, XML, Involved in the full life cycle of the project including analysis design,']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent = sent_tokenize(clean)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61395cb5",
   "metadata": {},
   "source": [
    "# Convert Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9837b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', ':', 'robert', '9475838374', 'email', ':', 'info', '@', 'qwikresume.com', 'website', ':', 'www.qwikresume.com', 'linkedin', ':', 'linkedin.com/qwikresume', 'address', ':', '1737', 'marshville', 'road', ',', 'alabama', '.', 'objective', 'over', '6', 'years', 'of', 'it', 'industry', 'experience', 'with', '4+', 'years', 'of', 'experience', 'as', 'mobile', 'application', 'developer', 'in', 'the', 'field', 'of', 'android', '.', 'experience', 'in', 'developing', 'front', 'end', 'applications', 'for', 'android', 'phones', '.', 'experience', 'developing', 'mobile', 'applications', 'on', 'android', 'platform', ',', 'building', 'custom', 'ui', 'using', 'views', ',', 'viewgroups', ',', 'layouts', ',', 'widgets', 'and', 'graphics', 'that', 'scale', 'based', 'on', 'the', 'screen', 'size', 'using', '9-', 'patch', 'images', ',', 'localization', ',', 'testing', 'and', 'publishing', 'the', 'applications', 'to', 'the', 'android', 'market', '.', 'skills', 'python', ',', 'java', ',', 'c', ',', 'javascript', ',', 'matlab', ',', 'r.', 'work', 'experience', 'android', 'developer', 'abc', 'corporation', 'january', '2011', 'march', '2012', 'environment', 'eclipse', 'ide', ',', 'android', 'studio', ',', 'genymotion', ',', 'java', ',', 'android', 'sdk', ',', 'android', 'development', 'tools', '(', 'adt', ')', ',', 'json', ',', 'xml', ',', 'involved', 'in', 'the', 'full', 'life', 'cycle', 'of', 'the', 'project', 'including', 'analysis', 'design', ',']\n"
     ]
    }
   ],
   "source": [
    "lis = []\n",
    "\n",
    "for word in tokens:\n",
    "    lis.append(word.lower())\n",
    "print(lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0d88fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ['python', 'matlab', 'c', 'javascript']\n"
     ]
    }
   ],
   "source": [
    "str = lis\n",
    "\n",
    "str1 = [\n",
    "\n",
    "   'python',\n",
    "    'c',\n",
    "    'javascript',\n",
    "    'matlab'\n",
    "    \n",
    "]\n",
    "\n",
    "a = set(str)\n",
    "b = set(str1)\n",
    "c = []\n",
    "\n",
    "for i in a:\n",
    "    if i in b:\n",
    "        c.append(i)\n",
    "print(\"Name\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c5bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "228cf070",
   "metadata": {},
   "source": [
    "# Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cebd537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\BALAJI\n",
      "[nltk_data]     K\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad232bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "569ac7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', ':', 'ROBERT', '9475838374', 'Email:', 'info@qwikresume.com', 'Website:', 'www.qwikresume.com', 'LinkedIn:', 'linkedin.com/qwikresume', 'Address:', '1737', 'Marshville', 'Road,', 'Alabama.', 'Objective', 'Over', '6', 'year', 'of', 'IT', 'industry', 'experience', 'with', '4+', 'year', 'of', 'experience', 'a', 'Mobile', 'application', 'developer', 'in', 'the', 'field', 'of', 'Android.', 'Experience', 'in', 'developing', 'front', 'end', 'application', 'for', 'Android', 'phones.', 'Experience', 'developing', 'mobile', 'application', 'on', 'Android', 'platform,', 'building', 'Custom', 'UI', 'using', 'Views,', 'ViewGroups,', 'Layouts,', 'Widgets', 'and', 'graphic', 'that', 'scale', 'based', 'on', 'the', 'screen', 'size', 'using', '9-', 'patch', 'images,', 'localization,', 'testing', 'and', 'publishing', 'the', 'application', 'to', 'the', 'Android', 'Market.', 'Skills', 'Python,', 'Java,', 'C,', 'Javascript,', 'Matlab,', 'R.', 'Work', 'Experience', 'Android', 'Developer', 'ABC', 'Corporation', 'January', '2011', 'March', '2012', 'Environment', 'Eclipse', 'IDE,', 'Android', 'Studio,', 'GenyMotion,', 'Java,', 'Android', 'SDK,', 'Android', 'Development', 'Tools', '(ADT),', 'JSON,', 'XML,', 'Involved', 'in', 'the', 'full', 'life', 'cycle', 'of', 'the', 'project', 'including', 'analysis', 'design,']\n"
     ]
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    lemmatize_text(line)\n",
    "lemman = lemmatize_text(clean)\n",
    "print(lemman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f9a4f",
   "metadata": {},
   "source": [
    "# After lemmatize for tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b422c170",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2c32f01734cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemman\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1274\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m         \"\"\"\n\u001b[1;32m-> 1276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \"\"\"\n\u001b[1;32m-> 1332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \"\"\"\n\u001b[1;32m-> 1332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \"\"\"\n\u001b[0;32m   1420\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[0mbefore_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m             \u001b[1;31m# Ignore matches that have already been captured by matches to the right of this match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbefore_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(lemman)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabcd96",
   "metadata": {},
   "source": [
    "### Trial extracting skills using Lemmintization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19098d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills ['Python,']\n"
     ]
    }
   ],
   "source": [
    "str = lemman\n",
    "\n",
    "str1 = [\n",
    "    \"Python,\",\n",
    "    'C',\n",
    "    'Matlab',\n",
    "]\n",
    "\n",
    "a = set(str)\n",
    "b = set(str1)\n",
    "c = []\n",
    "\n",
    "for i in a:\n",
    "    if i in b:\n",
    "        c.append(i)\n",
    "print(\"Skills\",c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e297e9",
   "metadata": {},
   "source": [
    "# trail\n",
    "resumeText = nltk.word_tokenize(clean)\n",
    "resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c778da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experience', 'objective', 'skills'}\n",
      "experience\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def extract_entity_sections(text):\n",
    "    \n",
    "    RESUME_SECTIONS_GRAD = [\n",
    "                        'accomplishments',\n",
    "                        'experience',\n",
    "                        'education',\n",
    "                        'interests',\n",
    "                        'projects',\n",
    "                        'professional experience',\n",
    "                        'publications',\n",
    "                        'skills',\n",
    "                        'certifications',\n",
    "                        'objective',\n",
    "                        'career objective',\n",
    "                        'summary',\n",
    "                        'leadership'\n",
    "                    ]\n",
    "\n",
    "    text_split = [i.strip() for i in text.split('\\n')]\n",
    "    entities = {}\n",
    "    key = False\n",
    "    for phrase in text_split:\n",
    "        if len(phrase) == 1:\n",
    "            p_key = phrase\n",
    "            print(p_key)\n",
    "        else:\n",
    "            p_key = set(phrase.lower().split())&set(RESUME_SECTIONS_GRAD)\n",
    "            print(p_key)\n",
    "        try:\n",
    "            p_key = list(p_key)[0]\n",
    "            print(p_key)\n",
    "        except IndexError:\n",
    "            pass\n",
    "        if p_key in RESUME_SECTIONS_GRAD:\n",
    "            entities[p_key] = []\n",
    "            key = p_key\n",
    "        elif key and phrase.strip():\n",
    "            entities[key].append(phrase)\n",
    "\n",
    "Skillset = extract_entity_sections(clean)\n",
    "print(Skillset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1777c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info@qwikresume.com\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    " \n",
    "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "def extract_emails(text):\n",
    "    return re.findall(EMAIL_REG, clean)\n",
    "text = clean\n",
    "emails = extract_emails(text)\n",
    " \n",
    "if emails:\n",
    "    mail = emails[0]\n",
    "    print(mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba47a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info@qwikresume.com\n"
     ]
    }
   ],
   "source": [
    "def extract_email(text):\n",
    "    \n",
    "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\",str(text))\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None\n",
    "print(extract_email(clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b9499",
   "metadata": {},
   "source": [
    "# trail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083ab64",
   "metadata": {},
   "source": [
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "NAME_PATTERN = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "\n",
    "def extract_name(text,matcher):\n",
    "    email = extract_email(text)\n",
    "    email = email.rsplit('@',1)[0]\n",
    "    email = re.sub(r'([^a-zA-Z]+?)',' ',email)\n",
    "    \n",
    "    f = string.capwords(email[0])\n",
    "    l = string.capwords(email[-1])\n",
    "    pattern = [NAME_PATTERN]\n",
    "    matcher.add('NAME', [pattern], on_match=None)\n",
    "    matches = matcher(text)\n",
    "    for match_id,start,end in matches:\n",
    "        span = text[start:end]\n",
    "        if f in span.text:\n",
    "            return span.text\n",
    "        elif l in span.text:\n",
    "            return span.text\n",
    "        elif f.upper() in span.text:\n",
    "            return span.text\n",
    "        elif l.upper() in span.text:\n",
    "            return span.text\n",
    "        \n",
    "extract_name(resumeText,matcher)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03bcf1",
   "metadata": {},
   "source": [
    "# trail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b74628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Marshville Road\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern], on_match=None)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text\n",
    "name = extract_name(clean)\n",
    "print('Name: ',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6fdb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Marshville Road'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern], on_match=None)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text\n",
    "    \n",
    "extract_name(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edd8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile Number:  9475838374\n"
     ]
    }
   ],
   "source": [
    "def extract_mobile_number(resume_text):\n",
    "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), resume_text)\n",
    "    \n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    "        if len(number) > 10:\n",
    "            return number\n",
    "        else:\n",
    "            return number\n",
    "mobile = extract_mobile_number(clean)\n",
    "print('Mobile Number: ',mobile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e1f51b",
   "metadata": {},
   "source": [
    "# trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "004c0c2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "free variable 'tokens' referenced before assignment in enclosing scope",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9c641ce57abc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mskillset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskillset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-9c641ce57abc>\u001b[0m in \u001b[0;36mskills\u001b[1;34m(nlp_text, noun_chunks)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnlp_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mskills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp_text\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'skills.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mskills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-9c641ce57abc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnlp_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mskills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp_text\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'skills.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mskills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: free variable 'tokens' referenced before assignment in enclosing scope"
     ]
    }
   ],
   "source": [
    "def skills(nlp_text,noun_chunks):\n",
    "    tokens = [tokens.text for token in nlp_text if not token.is_stop]\n",
    "    data = pd.read_csv(os.path.join(os.path.dirname(__file__),'skills.csv'))\n",
    "    skills = list(data.columns.values)\n",
    "    skillset = []\n",
    "    \n",
    "    #check for one-grams\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "    #check bigram trigram\n",
    "        for token in noun_chunks:\n",
    "        token = token.text.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19539420",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Skills'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2d3b43dbca42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskillset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Skills'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextract_skills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-2d3b43dbca42>\u001b[0m in \u001b[0;36mextract_skills\u001b[1;34m(resume_text)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# extract values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mskills\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSkills\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mskillset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'Skills'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # load the English model\n",
    "doc = nlp(clean)    # process a text and create a Doc object\n",
    "for chunk in doc.noun_chunks:       # iterate over the noun chunks in the Doc\n",
    "\n",
    "    noun_chunks = chunk.text\n",
    "\n",
    "def extract_skills(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "\n",
    "    # removing stop words and implementing word tokenization\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    colnames = ['Skills']\n",
    "    # reading the csv file\n",
    "    data =   [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'Java',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'English',\n",
    "    'Java',\n",
    "    'C',\n",
    "]\n",
    " \n",
    "    \n",
    "    # extract values\n",
    "    skills = data.Skills.tolist()\n",
    "    \n",
    "    skillset = []\n",
    "    \n",
    "    # check for one-grams (example: python)\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "   \n",
    "    for token in noun_chunks:\n",
    "        token = token.text.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
    "  \n",
    "print ('Skills',extract_skills(clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb724882",
   "metadata": {},
   "source": [
    "# Take Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c306a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###Edites\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # load the English model\n",
    "doc = nlp(clean)    # process a text and create a Doc object\n",
    "for chunk in doc.noun_chunks:       # iterate over the noun chunks in the Doc\n",
    "\n",
    "    noun_chunks = chunk.text\n",
    "\n",
    "def extract_skills(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "\n",
    "    # removing stop words and implementing word tokenization\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    \n",
    "    # reading the csv file\n",
    "    data =   [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'Java',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'English',\n",
    "    'Java',\n",
    "    'C',\n",
    "    'JavaScript'\n",
    "]\n",
    " \n",
    "    \n",
    "    # extract values\n",
    "    skills = data\n",
    "    \n",
    "    skillset = []\n",
    "    \n",
    "    # check for one-grams (example: python)\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "   \n",
    "        if noun_chunks in skills:\n",
    "            skillset.append(noun_chunks)\n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
    "  \n",
    "print ('Skills',extract_skills(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "48421e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM ITH Phone\n",
      "Email info\n",
      "Website www qwikresume\n",
      "com LinkedIn\n",
      "com qwikresume\n",
      "Address 1737 Marshville Road Alabama Objective\n",
      "Over 6 years\n",
      "IT industry experience\n",
      "4 years\n",
      "experience\n",
      "Mobile application developer\n",
      "the field\n",
      "Android Experience\n",
      "front end applications\n",
      "Android phones\n",
      "mobile applications\n",
      "Android platform building Custom UI\n",
      "Views ViewGroups Layouts Widg\n",
      "the screen size\n",
      "9 patch images localization testing\n",
      "the applications\n",
      "the Android Market Skills Python\n",
      "Java C Javascript Matlab R Work Experience\n",
      "Android Developer ABC Corporation\n",
      "Environment Eclipse IDE Android Studio GenyMotion\n",
      "Java Android SDK Android Development Tools ADT JSON XML\n",
      "the full life cycle\n",
      "the project\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")  # load the English model\n",
    "doc = nlp(clean)    # process a text and create a Doc object\n",
    "for chunk in doc.noun_chunks:       # iterate over the noun chunks in the Doc\n",
    "   print(chunk.text)\n",
    "\n",
    "noun_chunks = chunk.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff82e1b",
   "metadata": {},
   "source": [
    "# Take Domain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5713830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\BALAJI\n",
      "[nltk_data]     K\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Python'}\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import nltk\n",
    " \n",
    "nltk.download('stopwords')\n",
    " \n",
    "# you may read the database from a csv file or some other database\n",
    "SKILLS_DB = [\n",
    "    'machine learning',\n",
    "    'data science',\n",
    "    'Java',\n",
    "    'python',\n",
    "    'word',\n",
    "    'excel',\n",
    "    'English',\n",
    "    'Java',\n",
    "    'C',\n",
    "]\n",
    " \n",
    " \n",
    "from pdfminer.high_level import extract_text\n",
    " \n",
    " \n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    " \n",
    " \n",
    " \n",
    "def extract_skills(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    " \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in SKILLS_DB:\n",
    "            found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in SKILLS_DB:\n",
    "            found_skills.add(ngram)\n",
    " \n",
    "    return found_skills\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    text = extract_text_from_pdf('android-developer-1559034496.pdf')\n",
    "    skills = extract_skills(text)\n",
    " \n",
    "    print(skills)  # noqa: T001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb36243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile\n"
     ]
    }
   ],
   "source": [
    "def extract_address(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in['LOC','GPE']:\n",
    "            return ent.text\n",
    "        \n",
    "print(extract_address(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a901ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd132956",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1= NER(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d154b384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBERT SM ORG\n",
      "9475838374 CARDINAL\n",
      "LinkedIn PERSON\n",
      "1737 DATE\n",
      "Marshville Road, Alabama FAC\n",
      "6 years DATE\n",
      "4+ years DATE\n",
      "Mobile GPE\n",
      "Android ORG\n",
      "Android ORG\n",
      "Android ORG\n",
      "Custom UI ORG\n",
      "Views ORG\n",
      "ViewGroups ORG\n",
      "Layouts NORP\n",
      "Widgets ORG\n",
      "the Android Market ORG\n",
      "Skills Python ORG\n",
      "Matlab PERSON\n",
      "R. NORP\n",
      "January 2011 March 2012 DATE\n",
      "Android Studio PERSON\n",
      "GenyMotion ORG\n",
      "Java PERSON\n",
      "SDK ORG\n",
      "Android Development Tools ORG\n",
      "ADT ORG\n"
     ]
    }
   ],
   "source": [
    "for word in text1.ents:\n",
    "    print(word.text,word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "227a1f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Objects, vehicles, foods, etc. (not services)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PRODUCT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63839c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile\n"
     ]
    }
   ],
   "source": [
    "def extract_address(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in['LOC','GPE']:\n",
    "            return ent.text\n",
    "print(extract_address(clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56dfc50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-96-b7b0bc5c0b07>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-96-b7b0bc5c0b07>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \"email\": mail,\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " print( \n",
    "            \"email\"+mail,\"phone\"+ mobile,\"name\"+name,\"skills\"+skills,\n",
    "            \"Skillset\"+skillset,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ec1ea",
   "metadata": {},
   "source": [
    "# Convert lower case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b250076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a# .net', 'a# (axiom)', 'a-0 system', 'a+', 'a++', 'abap', 'abc', 'abc algol', 'able', 'abset', 'absys', 'acc', 'accent', 'ace dasl', 'acl2', 'act-iii', 'action!', 'actionscript', 'ada', 'adenine', 'agda', 'agilent vee', 'agora', 'aimms', 'alef', 'alf', 'algol 58', 'algol 60', 'algol 68', 'algol w', 'alice', 'alma-0', 'ambienttalk', 'amiga e', 'amos', 'ampl', 'apl', \"app inventor for android's visual block language\", 'applescript', 'arc', 'arexx', 'argus', 'aspectj', 'assembly language', 'ats', 'ateji px', 'autohotkey', 'autocoder', 'autoit', 'autolisp / visual lisp', 'averest', 'awk', 'axum', 'b', 'babbage', 'bash', 'basic', 'bc', 'bcpl', 'beanshell', 'batch (windows/dos)', 'bertrand', 'beta', 'bigwig', 'bistro', 'bitc', 'bliss', 'blue', 'bon', 'boo', 'boomerang', 'bourne shell', 'bash', 'ksh', 'brew', 'bpel', 'c', 'c--', 'c++', 'c#', 'c/al', 'caché objectscript', 'c shell', 'caml', 'candle', 'cayenne', 'cduce', 'cecil', 'cel', 'cesil', 'ceylon', 'cfengine', 'cfml', 'cg', 'ch', 'chapel', 'chain', 'charity', 'charm', 'chef', 'chill', 'chip-8', 'chomski', 'chuck', 'cics', 'cilk', 'cl', 'claire', 'clarion', 'clean', 'clipper', 'clist', 'clojure', 'clu', 'cms-2', 'cobol', 'cobra', 'code', 'coffeescript', 'cola', 'coldc', 'coldfusion', 'comal', 'combined programming language', 'comit', 'common intermediate language', 'common lisp', 'compass', 'component pascal', 'constraint handling rules', 'converge', 'cool', 'coq', 'coral 66', 'corn', 'corvision', 'cowsel', 'cpl', 'csh', 'csp', 'csound', 'cuda', 'curl', 'curry', 'cyclone', 'cython', 'd', 'dasl', 'dasl', 'dart', 'dataflex', 'datalog', 'datatrieve', 'dbase', 'dc', 'dcl', 'deesel', 'delphi', 'dinkc', 'dibol', 'dog', 'draco', 'drakon', 'dylan', 'dynamo', 'e', 'e#', 'ease', 'easy pl/i', 'easy programming language', 'easytrieve plus', 'ecmascript', 'edinburgh imp', 'egl', 'eiffel', 'elan', 'elixir', 'elm', 'emacs lisp', 'emerald', 'epigram', 'epl', 'erlang', 'es', 'escapade', 'escher', 'espol', 'esterel', 'etoys', 'euclid', 'euler', 'euphoria', 'euslisp robot programming language', 'cms exec', 'exec 2', 'executable uml', 'f', 'f#', 'factor', 'falcon', 'fancy', 'fantom', 'faust', 'felix', 'ferite', 'ffp', 'fjölnir', 'fl', 'flavors', 'flex', 'flow-matic', 'focal', 'focus', 'foil', 'formac', '@formula', 'forth', 'fortran', 'fortress', 'foxbase', 'foxpro', 'fp', 'fpr', 'franz lisp', 'frege', 'f-script', 'fsprog', 'g', 'google apps script', 'game maker language', 'gamemonkey script', 'gams', 'gap', 'g-code', 'genie', 'gdl', 'gibiane', 'gj', 'george', 'glsl', 'gnu e', 'gm', 'go', 'go!', 'goal', 'gödel', 'godiva', 'gom (good old mad)', 'goo', 'gosu', 'gotran', 'gpss', 'graphtalk', 'grass', 'groovy', 'hack (programming language)', 'hal/s', 'hamilton c shell', 'harbour', 'hartmann pipelines', 'haskell', 'haxe', 'high level assembly', 'hlsl', 'hop', 'hope', 'hugo', 'hume', 'hypertalk', 'ibm basic assembly language', 'ibm hascript', 'ibm informix-4gl', 'ibm rpg', 'ici', 'icon', 'id', 'idl', 'idris', 'imp', 'inform', 'io', 'ioke', 'ipl', 'iptscrae', 'islisp', 'ispf', 'iswim', 'j', 'j#', 'j++', 'jade', 'jako', 'jal', 'janus', 'jass', 'java', 'javascript', 'jcl', 'jean', 'join java', 'joss', 'joule', 'jovial', 'joy', 'jscript', 'jscript .net', 'javafx script', 'julia', 'jython', 'k', 'kaleidoscope', 'karel', 'karel++', 'kee', 'kixtart', 'kif', 'kojo', 'kotlin', 'krc', 'krl', 'kuka', 'krypton', 'ksh', 'l', 'l# .net', 'labview', 'ladder', 'lagoona', 'lansa', 'lasso', 'latex', 'lava', 'lc-3', 'leda', 'legoscript', 'lil', 'lilypond', 'limbo', 'limnor', 'linc', 'lingo', 'linoleum', 'lis', 'lisa', 'lisaac', 'lisp', 'lite-c', 'lithe', 'little b', 'logo', 'logtalk', 'lpc', 'lse', 'lsl', 'livecode', 'livescript', 'lua', 'lucid', 'lustre', 'lyapas', 'lynx', 'm2001', 'm4', 'machine code', 'mad', 'mad/i', 'magik', 'magma', 'make', 'maple', 'mapper', 'mark-iv', 'mary', 'masm microsoft assembly x86', 'mathematica', 'matlab', 'maxima', 'macsyma', 'max', 'maxscript', 'maya (mel)', 'mdl', 'mercury', 'mesa', 'metacard', 'metafont', 'metal', 'microcode', 'microscript', 'miis', 'millscript', 'mimic', 'mirah', 'miranda', 'miva script', 'ml', 'moby', 'model 204', 'modelica', 'modula', 'modula-2', 'modula-3', 'mohol', 'moo', 'mortran', 'mouse', 'mpd', 'cil', 'msl', 'mumps', 'nasm', 'natural', 'napier88', 'neko', 'nemerle', 'nesc', 'nesl', 'net.data', 'netlogo', 'netrexx', 'newlisp', 'newp', 'newspeak', 'newtonscript', 'ngl', 'nial', 'nice', 'nickle', 'nim', 'npl', 'not exactly c', 'not quite c', 'nsis', 'nu', 'nwscript', 'nxt-g', 'o:xml', 'oak', 'oberon', 'obix', 'obj2', 'object lisp', 'objectlogo', 'object rexx', 'object pascal', 'objective-c', 'objective-j', 'obliq', 'obol', 'ocaml', 'occam', 'occam-π', 'octave', 'omnimark', 'onyx', 'opa', 'opal', 'opencl', 'openedge abl', 'opl', 'ops5', 'optimj', 'orc', 'orca/modula-2', 'oriel', 'orwell', 'oxygene', 'oz', 'p#', 'parasail (programming language)', 'pari/gp', 'pascal', 'pawn', 'pcastl', 'pcf', 'pearl', 'peoplecode', 'perl', 'pdl', 'php', 'phrogram', 'pico', 'picolisp', 'pict', 'pike', 'pikt', 'pilot', 'pipelines', 'pizza', 'pl-11', 'pl/0', 'pl/b', 'pl/c', 'pl/i', 'pl/m', 'pl/p', 'pl/sql', 'pl360', 'planc', 'plankalkül', 'planner', 'plex', 'plexil', 'plus', 'pop-11', 'postscript', 'portable', 'powerhouse', 'powerbuilder', 'powershell', 'ppl', 'processing', 'processing.js', 'prograph', 'proiv', 'prolog', 'promal', 'promela', 'prose modeling language', 'protel', 'providex', 'pro*c', 'pure', 'python', 'q (equational programming language)', 'q (programming language from kx systems)', 'qalb', 'qtscript', 'quakec', 'qpl', 'r', 'r++', 'racket', 'rapid', 'rapira', 'ratfiv', 'ratfor', 'rc', 'rebol', 'red', 'redcode', 'refal', 'reia', 'revolution', 'rex', 'rexx', 'rlab', 'robotc', 'roop', 'rpg', 'rpl', 'rsl', 'rtl/2', 'ruby', 'runescript', 'rust', 's', 's2', 's3', 's-lang', 's-plus', 'sa-c', 'sabretalk', 'sail', 'salsa', 'sam76', 'sas', 'sasl', 'sather', 'sawzall', 'sbl', 'scala', 'scheme', 'scilab', 'scratch', 'script.net', 'sed', 'seed7', 'self', 'sensetalk', 'sequencel', 'setl', 'shift script', 'simpol', 'signal', 'simple', 'simscript', 'simula', 'simulink', 'sisal', 'slip', 'small', 'smalltalk', 'small basic', 'sml', 'snap!', 'snobol', 'spitbol', 'snowball', 'sol', 'span', 'spark', 'speedcode', 'spin', 'sp/k', 'sps', 'squeak', 'squirrel', 'sr', 's/sl', 'stackless python', 'starlogo', 'strand', 'stata', 'stateflow', 'subtext', 'supercollider', 'supertalk', 'swift (apple programming language)', 'swift (parallel scripting language)', 'sympl', 'synccharts', 'systemverilog', 't', 'tacl', 'tacpol', 'tads', 'tal', 'tcl', 'tea', 'teco', 'telcomp', 'tex', 'tex', 'tie', 'timber', 'tmg', 'tom', 'tom', 'topspeed', 'tpu', 'trac', 'ttm', 't-sql', 'ttcn', 'turing', 'tutor', 'txl', 'typescript', 'turbo c++', 'ubercode', 'ucsd pascal', 'umple', 'unicon', 'uniface', 'unity', 'unix shell', 'unrealscript', 'vala', 'vba', 'vbscript', 'verilog', 'vhdl', 'visual basic', 'visual basic .net', 'visual dataflex', 'visual dialogscript', 'visual fortran', 'visual foxpro', 'visual j++', 'visual j#', 'visual objects', 'visual prolog', 'vsxu', 'vvvv', 'watfiv, watfor', 'webdna', 'webql', 'windows powershell', 'winbatch', 'wolfram', 'wyvern', 'x++', 'x#', 'x10', 'xbl', 'xc', 'xmos architecture', 'xharbour', 'xl', 'xojo', 'xotcl', 'xpl', 'xpl0', 'xquery', 'xsb', 'xslt', 'xpath', 'xtend', 'yorick', 'yql', 'z notation', 'zeno', 'zopl', 'zpl']\n"
     ]
    }
   ],
   "source": [
    "lang = [\"A# .NET\",\"A# (Axiom)\",\"A-0 System\",\"A+\",\"A++\",\"ABAP\",\"ABC\",\"ABC ALGOL\",\"ABLE\",\"ABSET\",\"ABSYS\",\"ACC\",\"Accent\",\"Ace DASL\",\"ACL2\",\"ACT-III\",\"Action!\",\"ActionScript\",\"Ada\",\"Adenine\",\"Agda\",\"Agilent VEE\",\"Agora\",\"AIMMS\",\"Alef\",\"ALF\",\"ALGOL 58\",\"ALGOL 60\",\"ALGOL 68\",\"ALGOL W\",\"Alice\",\"Alma-0\",\"AmbientTalk\",\"Amiga E\",\"AMOS\",\"AMPL\",\"APL\",\"App Inventor for Android's visual block language\",\"AppleScript\",\"Arc\",\"ARexx\",\"Argus\",\"AspectJ\",\"Assembly language\",\"ATS\",\"Ateji PX\",\"AutoHotkey\",\"Autocoder\",\"AutoIt\",\"AutoLISP / Visual LISP\",\"Averest\",\"AWK\",\"Axum\",\"B\",\"Babbage\",\"Bash\",\"BASIC\",\"bc\",\"BCPL\",\"BeanShell\",\"Batch (Windows/Dos)\",\"Bertrand\",\"BETA\",\"Bigwig\",\"Bistro\",\"BitC\",\"BLISS\",\"Blue\",\"Bon\",\"Boo\",\"Boomerang\",\"Bourne shell\",\"bash\",\"ksh\",\"BREW\",\"BPEL\",\"C\",\"C--\",\"C++\",\"C#\",\"C/AL\",\"Caché ObjectScript\",\"C Shell\",\"Caml\",\"Candle\",\"Cayenne\",\"CDuce\",\"Cecil\",\"Cel\",\"Cesil\",\"Ceylon\",\"CFEngine\",\"CFML\",\"Cg\",\"Ch\",\"Chapel\",\"CHAIN\",\"Charity\",\"Charm\",\"Chef\",\"CHILL\",\"CHIP-8\",\"chomski\",\"ChucK\",\"CICS\",\"Cilk\",\"CL\",\"Claire\",\"Clarion\",\"Clean\",\"Clipper\",\"CLIST\",\"Clojure\",\"CLU\",\"CMS-2\",\"COBOL\",\"Cobra\",\"CODE\",\"CoffeeScript\",\"Cola\",\"ColdC\",\"ColdFusion\",\"COMAL\",\"Combined Programming Language\",\"COMIT\",\"Common Intermediate Language\",\"Common Lisp\",\"COMPASS\",\"Component Pascal\",\"Constraint Handling Rules\",\"Converge\",\"Cool\",\"Coq\",\"Coral 66\",\"Corn\",\"CorVision\",\"COWSEL\",\"CPL\",\"csh\",\"CSP\",\"Csound\",\"CUDA\",\"Curl\",\"Curry\",\"Cyclone\",\"Cython\",\"D\",\"DASL\",\"DASL\",\"Dart\",\"DataFlex\",\"Datalog\",\"DATATRIEVE\",\"dBase\",\"dc\",\"DCL\",\"Deesel\",\"Delphi\",\"DinkC\",\"DIBOL\",\"Dog\",\"Draco\",\"DRAKON\",\"Dylan\",\"DYNAMO\",\"E\",\"E#\",\"Ease\",\"Easy PL/I\",\"Easy Programming Language\",\"EASYTRIEVE PLUS\",\"ECMAScript\",\"Edinburgh IMP\",\"EGL\",\"Eiffel\",\"ELAN\",\"Elixir\",\"Elm\",\"Emacs Lisp\",\"Emerald\",\"Epigram\",\"EPL\",\"Erlang\",\"es\",\"Escapade\",\"Escher\",\"ESPOL\",\"Esterel\",\"Etoys\",\"Euclid\",\"Euler\",\"Euphoria\",\"EusLisp Robot Programming Language\",\"CMS EXEC\",\"EXEC 2\",\"Executable UML\",\"F\",\"F#\",\"Factor\",\"Falcon\",\"Fancy\",\"Fantom\",\"FAUST\",\"Felix\",\"Ferite\",\"FFP\",\"Fjölnir\",\"FL\",\"Flavors\",\"Flex\",\"FLOW-MATIC\",\"FOCAL\",\"FOCUS\",\"FOIL\",\"FORMAC\",\"@Formula\",\"Forth\",\"Fortran\",\"Fortress\",\"FoxBase\",\"FoxPro\",\"FP\",\"FPr\",\"Franz Lisp\",\"Frege\",\"F-Script\",\"FSProg\",\"G\",\"Google Apps Script\",\"Game Maker Language\",\"GameMonkey Script\",\"GAMS\",\"GAP\",\"G-code\",\"Genie\",\"GDL\",\"Gibiane\",\"GJ\",\"GEORGE\",\"GLSL\",\"GNU E\",\"GM\",\"Go\",\"Go!\",\"GOAL\",\"Gödel\",\"Godiva\",\"GOM (Good Old Mad)\",\"Goo\",\"Gosu\",\"GOTRAN\",\"GPSS\",\"GraphTalk\",\"GRASS\",\"Groovy\",\"Hack (programming language)\",\"HAL/S\",\"Hamilton C shell\",\"Harbour\",\"Hartmann pipelines\",\"Haskell\",\"Haxe\",\"High Level Assembly\",\"HLSL\",\"Hop\",\"Hope\",\"Hugo\",\"Hume\",\"HyperTalk\",\"IBM Basic assembly language\",\"IBM HAScript\",\"IBM Informix-4GL\",\"IBM RPG\",\"ICI\",\"Icon\",\"Id\",\"IDL\",\"Idris\",\"IMP\",\"Inform\",\"Io\",\"Ioke\",\"IPL\",\"IPTSCRAE\",\"ISLISP\",\"ISPF\",\"ISWIM\",\"J\",\"J#\",\"J++\",\"JADE\",\"Jako\",\"JAL\",\"Janus\",\"JASS\",\"Java\",\"JavaScript\",\"JCL\",\"JEAN\",\"Join Java\",\"JOSS\",\"Joule\",\"JOVIAL\",\"Joy\",\"JScript\",\"JScript .NET\",\"JavaFX Script\",\"Julia\",\"Jython\",\"K\",\"Kaleidoscope\",\"Karel\",\"Karel++\",\"KEE\",\"Kixtart\",\"KIF\",\"Kojo\",\"Kotlin\",\"KRC\",\"KRL\",\"KUKA\",\"KRYPTON\",\"ksh\",\"L\",\"L# .NET\",\"LabVIEW\",\"Ladder\",\"Lagoona\",\"LANSA\",\"Lasso\",\"LaTeX\",\"Lava\",\"LC-3\",\"Leda\",\"Legoscript\",\"LIL\",\"LilyPond\",\"Limbo\",\"Limnor\",\"LINC\",\"Lingo\",\"Linoleum\",\"LIS\",\"LISA\",\"Lisaac\",\"Lisp\",\"Lite-C\",\"Lithe\",\"Little b\",\"Logo\",\"Logtalk\",\"LPC\",\"LSE\",\"LSL\",\"LiveCode\",\"LiveScript\",\"Lua\",\"Lucid\",\"Lustre\",\"LYaPAS\",\"Lynx\",\"M2001\",\"M4\",\"Machine code\",\"MAD\",\"MAD/I\",\"Magik\",\"Magma\",\"make\",\"Maple\",\"MAPPER\",\"MARK-IV\",\"Mary\",\"MASM Microsoft Assembly x86\",\"Mathematica\",\"MATLAB\",\"Maxima\",\"Macsyma\",\"Max\",\"MaxScript\",\"Maya (MEL)\",\"MDL\",\"Mercury\",\"Mesa\",\"Metacard\",\"Metafont\",\"MetaL\",\"Microcode\",\"MicroScript\",\"MIIS\",\"MillScript\",\"MIMIC\",\"Mirah\",\"Miranda\",\"MIVA Script\",\"ML\",\"Moby\",\"Model 204\",\"Modelica\",\"Modula\",\"Modula-2\",\"Modula-3\",\"Mohol\",\"MOO\",\"Mortran\",\"Mouse\",\"MPD\",\"CIL\",\"MSL\",\"MUMPS\",\"NASM\",\"NATURAL\",\"Napier88\",\"Neko\",\"Nemerle\",\"nesC\",\"NESL\",\"Net.Data\",\"NetLogo\",\"NetRexx\",\"NewLISP\",\"NEWP\",\"Newspeak\",\"NewtonScript\",\"NGL\",\"Nial\",\"Nice\",\"Nickle\",\"Nim\",\"NPL\",\"Not eXactly C\",\"Not Quite C\",\"NSIS\",\"Nu\",\"NWScript\",\"NXT-G\",\"o:XML\",\"Oak\",\"Oberon\",\"Obix\",\"OBJ2\",\"Object Lisp\",\"ObjectLOGO\",\"Object REXX\",\"Object Pascal\",\"Objective-C\",\"Objective-J\",\"Obliq\",\"Obol\",\"OCaml\",\"occam\",\"occam-π\",\"Octave\",\"OmniMark\",\"Onyx\",\"Opa\",\"Opal\",\"OpenCL\",\"OpenEdge ABL\",\"OPL\",\"OPS5\",\"OptimJ\",\"Orc\",\"ORCA/Modula-2\",\"Oriel\",\"Orwell\",\"Oxygene\",\"Oz\",\"P#\",\"ParaSail (programming language)\",\"PARI/GP\",\"Pascal\",\"Pawn\",\"PCASTL\",\"PCF\",\"PEARL\",\"PeopleCode\",\"Perl\",\"PDL\",\"PHP\",\"Phrogram\",\"Pico\",\"Picolisp\",\"Pict\",\"Pike\",\"PIKT\",\"PILOT\",\"Pipelines\",\"Pizza\",\"PL-11\",\"PL/0\",\"PL/B\",\"PL/C\",\"PL/I\",\"PL/M\",\"PL/P\",\"PL/SQL\",\"PL360\",\"PLANC\",\"Plankalkül\",\"Planner\",\"PLEX\",\"PLEXIL\",\"Plus\",\"POP-11\",\"PostScript\",\"PortablE\",\"Powerhouse\",\"PowerBuilder\",\"PowerShell\",\"PPL\",\"Processing\",\"Processing.js\",\"Prograph\",\"PROIV\",\"Prolog\",\"PROMAL\",\"Promela\",\"PROSE modeling language\",\"PROTEL\",\"ProvideX\",\"Pro*C\",\"Pure\",\"Python\",\"Q (equational programming language)\",\"Q (programming language from Kx Systems)\",\"Qalb\",\"QtScript\",\"QuakeC\",\"QPL\",\"R\",\"R++\",\"Racket\",\"RAPID\",\"Rapira\",\"Ratfiv\",\"Ratfor\",\"rc\",\"REBOL\",\"Red\",\"Redcode\",\"REFAL\",\"Reia\",\"Revolution\",\"rex\",\"REXX\",\"Rlab\",\"RobotC\",\"ROOP\",\"RPG\",\"RPL\",\"RSL\",\"RTL/2\",\"Ruby\",\"RuneScript\",\"Rust\",\"S\",\"S2\",\"S3\",\"S-Lang\",\"S-PLUS\",\"SA-C\",\"SabreTalk\",\"SAIL\",\"SALSA\",\"SAM76\",\"SAS\",\"SASL\",\"Sather\",\"Sawzall\",\"SBL\",\"Scala\",\"Scheme\",\"Scilab\",\"Scratch\",\"Script.NET\",\"Sed\",\"Seed7\",\"Self\",\"SenseTalk\",\"SequenceL\",\"SETL\",\"Shift Script\",\"SIMPOL\",\"SIGNAL\",\"SiMPLE\",\"SIMSCRIPT\",\"Simula\",\"Simulink\",\"SISAL\",\"SLIP\",\"SMALL\",\"Smalltalk\",\"Small Basic\",\"SML\",\"Snap!\",\"SNOBOL\",\"SPITBOL\",\"Snowball\",\"SOL\",\"Span\",\"SPARK\",\"Speedcode\",\"SPIN\",\"SP/k\",\"SPS\",\"Squeak\",\"Squirrel\",\"SR\",\"S/SL\",\"Stackless Python\",\"Starlogo\",\"Strand\",\"Stata\",\"Stateflow\",\"Subtext\",\"SuperCollider\",\"SuperTalk\",\"Swift (Apple programming language)\",\"Swift (parallel scripting language)\",\"SYMPL\",\"SyncCharts\",\"SystemVerilog\",\"T\",\"TACL\",\"TACPOL\",\"TADS\",\"TAL\",\"Tcl\",\"Tea\",\"TECO\",\"TELCOMP\",\"TeX\",\"TEX\",\"TIE\",\"Timber\",\"TMG\",\"Tom\",\"TOM\",\"Topspeed\",\"TPU\",\"Trac\",\"TTM\",\"T-SQL\",\"TTCN\",\"Turing\",\"TUTOR\",\"TXL\",\"TypeScript\",\"Turbo C++\",\"Ubercode\",\"UCSD Pascal\",\"Umple\",\"Unicon\",\"Uniface\",\"UNITY\",\"Unix shell\",\"UnrealScript\",\"Vala\",\"VBA\",\"VBScript\",\"Verilog\",\"VHDL\",\"Visual Basic\",\"Visual Basic .NET\",\"Visual DataFlex\",\"Visual DialogScript\",\"Visual Fortran\",\"Visual FoxPro\",\"Visual J++\",\"Visual J#\",\"Visual Objects\",\"Visual Prolog\",\"VSXu\",\"Vvvv\",\"WATFIV, WATFOR\",\"WebDNA\",\"WebQL\",\"Windows PowerShell\",\"Winbatch\",\"Wolfram\",\"Wyvern\",\"X++\",\"X#\",\"X10\",\"XBL\",\"XC\",\"XMOS architecture\",\"xHarbour\",\"XL\",\"Xojo\",\"XOTcl\",\"XPL\",\"XPL0\",\"XQuery\",\"XSB\",\"XSLT\",\"XPath\",\"Xtend\",\"Yorick\",\"YQL\",\"Z notation\",\"Zeno\",\"ZOPL\",\"ZPL\"]\n",
    "lis = []\n",
    "\n",
    "for word in lang:\n",
    "    lis.append(word.lower())\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b196ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'n', 'a', 'm', 'e', ' ', ':', ' ', 'r', 'o', 'b', 'e', 'r', 't', ' ', '9', '4', '7', '5', '8', '3', '8', '3', '7', '4', ' ', 'e', 'm', 'a', 'i', 'l', ':', ' ', 'i', 'n', 'f', 'o', '@', 'q', 'w', 'i', 'k', 'r', 'e', 's', 'u', 'm', 'e', '.', 'c', 'o', 'm', ' ', 'w', 'e', 'b', 's', 'i', 't', 'e', ':', ' ', 'w', 'w', 'w', '.', 'q', 'w', 'i', 'k', 'r', 'e', 's', 'u', 'm', 'e', '.', 'c', 'o', 'm', ' ', 'l', 'i', 'n', 'k', 'e', 'd', 'i', 'n', ':', ' ', 'l', 'i', 'n', 'k', 'e', 'd', 'i', 'n', '.', 'c', 'o', 'm', '/', 'q', 'w', 'i', 'k', 'r', 'e', 's', 'u', 'm', 'e', ' ', 'a', 'd', 'd', 'r', 'e', 's', 's', ':', ' ', '1', '7', '3', '7', ' ', 'm', 'a', 'r', 's', 'h', 'v', 'i', 'l', 'l', 'e', ' ', 'r', 'o', 'a', 'd', ',', ' ', 'a', 'l', 'a', 'b', 'a', 'm', 'a', '.', ' ', 'o', 'b', 'j', 'e', 'c', 't', 'i', 'v', 'e', ' ', 'o', 'v', 'e', 'r', ' ', '6', ' ', 'y', 'e', 'a', 'r', 's', ' ', 'o', 'f', ' ', 'i', 't', ' ', 'i', 'n', 'd', 'u', 's', 't', 'r', 'y', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'e', 'n', 'c', 'e', ' ', 'w', 'i', 't', 'h', ' ', '4', '+', ' ', 'y', 'e', 'a', 'r', 's', ' ', 'o', 'f', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'e', 'n', 'c', 'e', ' ', 'a', 's', ' ', 'm', 'o', 'b', 'i', 'l', 'e', ' ', 'a', 'p', 'p', 'l', 'i', 'c', 'a', 't', 'i', 'o', 'n', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'e', 'r', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'f', 'i', 'e', 'l', 'd', ' ', 'o', 'f', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', '.', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'e', 'n', 'c', 'e', ' ', 'i', 'n', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'i', 'n', 'g', ' ', 'f', 'r', 'o', 'n', 't', ' ', 'e', 'n', 'd', ' ', 'a', 'p', 'p', 'l', 'i', 'c', 'a', 't', 'i', 'o', 'n', 's', ' ', 'f', 'o', 'r', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 'p', 'h', 'o', 'n', 'e', 's', '.', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'e', 'n', 'c', 'e', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'i', 'n', 'g', ' ', 'm', 'o', 'b', 'i', 'l', 'e', ' ', 'a', 'p', 'p', 'l', 'i', 'c', 'a', 't', 'i', 'o', 'n', 's', ' ', 'o', 'n', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 'p', 'l', 'a', 't', 'f', 'o', 'r', 'm', ',', ' ', 'b', 'u', 'i', 'l', 'd', 'i', 'n', 'g', ' ', 'c', 'u', 's', 't', 'o', 'm', ' ', 'u', 'i', ' ', 'u', 's', 'i', 'n', 'g', ' ', 'v', 'i', 'e', 'w', 's', ',', ' ', 'v', 'i', 'e', 'w', 'g', 'r', 'o', 'u', 'p', 's', ',', ' ', 'l', 'a', 'y', 'o', 'u', 't', 's', ',', ' ', 'w', 'i', 'd', 'g', 'e', 't', 's', ' ', 'a', 'n', 'd', ' ', 'g', 'r', 'a', 'p', 'h', 'i', 'c', 's', ' ', 't', 'h', 'a', 't', ' ', 's', 'c', 'a', 'l', 'e', ' ', 'b', 'a', 's', 'e', 'd', ' ', 'o', 'n', ' ', 't', 'h', 'e', ' ', 's', 'c', 'r', 'e', 'e', 'n', ' ', 's', 'i', 'z', 'e', ' ', 'u', 's', 'i', 'n', 'g', ' ', '9', '-', ' ', 'p', 'a', 't', 'c', 'h', ' ', 'i', 'm', 'a', 'g', 'e', 's', ',', ' ', 'l', 'o', 'c', 'a', 'l', 'i', 'z', 'a', 't', 'i', 'o', 'n', ',', ' ', 't', 'e', 's', 't', 'i', 'n', 'g', ' ', 'a', 'n', 'd', ' ', 'p', 'u', 'b', 'l', 'i', 's', 'h', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'a', 'p', 'p', 'l', 'i', 'c', 'a', 't', 'i', 'o', 'n', 's', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 'm', 'a', 'r', 'k', 'e', 't', '.', ' ', 's', 'k', 'i', 'l', 'l', 's', ' ', 'p', 'y', 't', 'h', 'o', 'n', ',', ' ', 'j', 'a', 'v', 'a', ',', ' ', 'c', ',', ' ', 'j', 'a', 'v', 'a', 's', 'c', 'r', 'i', 'p', 't', ',', ' ', 'm', 'a', 't', 'l', 'a', 'b', ',', ' ', 'r', '.', ' ', 'w', 'o', 'r', 'k', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'e', 'n', 'c', 'e', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'e', 'r', ' ', 'a', 'b', 'c', ' ', 'c', 'o', 'r', 'p', 'o', 'r', 'a', 't', 'i', 'o', 'n', ' ', 'j', 'a', 'n', 'u', 'a', 'r', 'y', ' ', '2', '0', '1', '1', ' ', 'm', 'a', 'r', 'c', 'h', ' ', '2', '0', '1', '2', ' ', 'e', 'n', 'v', 'i', 'r', 'o', 'n', 'm', 'e', 'n', 't', ' ', 'e', 'c', 'l', 'i', 'p', 's', 'e', ' ', 'i', 'd', 'e', ',', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 's', 't', 'u', 'd', 'i', 'o', ',', ' ', 'g', 'e', 'n', 'y', 'm', 'o', 't', 'i', 'o', 'n', ',', ' ', 'j', 'a', 'v', 'a', ',', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 's', 'd', 'k', ',', ' ', 'a', 'n', 'd', 'r', 'o', 'i', 'd', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 't', 'o', 'o', 'l', 's', ' ', '(', 'a', 'd', 't', ')', ',', ' ', 'j', 's', 'o', 'n', ',', ' ', 'x', 'm', 'l', ',', ' ', 'i', 'n', 'v', 'o', 'l', 'v', 'e', 'd', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'f', 'u', 'l', 'l', ' ', 'l', 'i', 'f', 'e', ' ', 'c', 'y', 'c', 'l', 'e', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'i', 'n', 'c', 'l', 'u', 'd', 'i', 'n', 'g', ' ', 'a', 'n', 'a', 'l', 'y', 's', 'i', 's', ' ', 'd', 'e', 's', 'i', 'g', 'n', ',', ' ']\n"
     ]
    }
   ],
   "source": [
    "lis = []\n",
    "for word in clean:\n",
    "    lis.append(word.lower())\n",
    "print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be39d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
